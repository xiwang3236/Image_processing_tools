{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIE6krnLDB4i",
        "outputId": "d050c59a-1a26-4ce9-c7d7-f01bdc99bc3f"
      },
      "outputs": [],
      "source": [
        "# For colab training\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# import os\n",
        "# repo_path = '/content/drive/MyDrive/projects/Celpose'\n",
        "# if not os.path.exists(repo_path):\n",
        "#     os.makedirs(repo_path)\n",
        "# os.chdir(repo_path)\n",
        "\n",
        "# !pip install cellpose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Single file API segmentation test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "16KkSuxN3ZAI"
      },
      "outputs": [],
      "source": [
        "image_input_file = r\"D:\\Junwoo\\Projects\\Image_processing_tools\\Image_processing_tools\\input\\cellpose\\E3H5_Round1_DAPI_tile2_inference.tif\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2ab1QyA3ZAK",
        "outputId": "a2c9f4b9-d29d-4cf7-bbb5-ad16c10ebfbc"
      },
      "outputs": [],
      "source": [
        "import tifffile\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Read the image\n",
        "img = tifffile.imread(image_input_file)\n",
        "\n",
        "# Print the shape of the image\n",
        "print(f\"Image shape: {img.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "zZ2kk0W63ZAL",
        "outputId": "be8b3055-1ba8-4dd9-d529-8fa57f069e09"
      },
      "outputs": [],
      "source": [
        "# Specify the layer index to visualize (0-based indexing)\n",
        "layer_index = 300  # Change this to the specific layer you want to visualize\n",
        "\n",
        "# Check if the layer index is within bounds\n",
        "if 0 <= layer_index < img.shape[0]:\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(img[layer_index, :, :], cmap='gray')\n",
        "    plt.title(f'Layer {layer_index + 1}')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(f\"Invalid layer index: {layer_index}. Please choose a value between 0 and {img.shape[0] - 1}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "eA68NLMMvWRe"
      },
      "outputs": [],
      "source": [
        "from cellpose import denoise, models, io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# model set up\n",
        "denoise_model = denoise.DenoiseModel(gpu=True, model_type='denoise_nuclei',  diam_mean=20.0)\n",
        "model = models.CellposeModel(gpu=True, model_type = \"nuclei\" , diam_mean=20.0)\n",
        "\n",
        "\n",
        "# denoise\n",
        "imgs_dn = denoise_model.eval(img, batch_size=8,\n",
        "                            channel_axis=None,\n",
        "                            # z_axis=0,\n",
        "                            normalize=True,\n",
        "                            rescale=None,\n",
        "                            diameter=20,\n",
        "                            tile=True,\n",
        "                            do_3D=True,\n",
        "                            tile_overlap=0.1,\n",
        "                            bsize=224)\n",
        "\n",
        "# segmentation\n",
        "masks, flows, styles = model.eval(\n",
        "    x=imgs_dn,  # Your input image array\n",
        "    batch_size=8,\n",
        "    do_3D=True,       # Enable 3D segmentation\n",
        "    diameter=20.0,\n",
        "    channel_axis = None,\n",
        "    # anisotropy=2.0    # Adjust anisotropy if needed\n",
        ")\n",
        "\n",
        "print(\"output image shape is: \", masks.shape)\n",
        "\n",
        "# save the masks as tif file\n",
        "io.save_masks(\n",
        "    images=[img],  # List containing the image\n",
        "    masks=[masks],            # List containing the mask\n",
        "    flows=[flows],            # List containing the flows\n",
        "    file_names=['output/Cellpose_output'],  # Base filename for saving\n",
        "    png=False,                # Disable saving as PNG\n",
        "    tif=True,                 # Enable saving as TIFF\n",
        "    channels=[0, 0],           # Channels used in Cellpose\n",
        "    # ... other parameters if needed ...\n",
        ")\n",
        "\n",
        "# print(f\"Mask number n saved as 'cp_masks_{img_name}.tif'\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add this before saving to debug\n",
        "print(\"Masks shape:\", masks.shape)\n",
        "print(\"Masks dtype:\", masks.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ticIpIOHFcK2"
      },
      "outputs": [],
      "source": [
        "# # Save the segmentation output\n",
        "# io.masks_flows_to_seg(\n",
        "#     images=[img],  # List containing the image\n",
        "#     masks=[masks],            # List containing the mask\n",
        "#     flows=[flows],            # List containing the flows\n",
        "#     file_names=['Image_processing_tools/output/segmented_output_seg.npy'],  # Base filename for saving\n",
        "#     diams=30.0,              # Diameter used in Cellpose\n",
        "\n",
        "# )\n",
        "\n",
        "# print(\"Segmentation output saved to 'segmented_output_seg.npy'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# For Loop training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import tifffile as tiff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from cellpose import denoise, models, io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO test\n",
        "from skimage import measure \n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Junwoo\\Conda\\envs\\cellpose\\lib\\site-packages\\cellpose\\resnet_torch.py:271: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(filename, map_location=device)\n"
          ]
        }
      ],
      "source": [
        "# Initialize models at the beginning\n",
        "denoise_model = denoise.DenoiseModel(gpu=True, model_type='denoise_nuclei', diam_mean=19.0)\n",
        "cellpose_model = models.CellposeModel(gpu=True, model_type='nuclei', diam_mean=19.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def denoise_and_segment_image(img, img_name, output_path, denoise_model, cellpose_model):\n",
        "    \"\"\"\n",
        "    Perform denoising and segmentation on a 3D image using Cellpose.\n",
        "\n",
        "    Parameters:\n",
        "    - img (numpy.ndarray): Input image array to process.\n",
        "    - img_name (str): Name of the input image (for logging and saving purposes).\n",
        "    - output_path (str): Base path to save the output.\n",
        "    - denoise_model: Pre-initialized denoising model.\n",
        "    - cellpose_model: Pre-initialized Cellpose segmentation model.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    # Display input image information\n",
        "    print(f\"Processing file: {img_name}, shape: {img.shape}\")\n",
        "\n",
        "    # Perform denoising\n",
        "    imgs_dn = denoise_model.eval(\n",
        "        img,\n",
        "        batch_size=4,\n",
        "        channel_axis=None,\n",
        "        normalize=True,\n",
        "        rescale=None,\n",
        "        diameter=19, # denoise_model.diam_mean\n",
        "        tile=True,\n",
        "        do_3D=True,\n",
        "        tile_overlap=0.1,\n",
        "        bsize=224\n",
        "    )\n",
        "\n",
        "    print(\"Denoise Down!\")\n",
        "\n",
        "    # Perform segmentation\n",
        "    masks, flows, styles = cellpose_model.eval(\n",
        "        x=imgs_dn,\n",
        "        batch_size=8,\n",
        "        do_3D=True,\n",
        "        diameter=cellpose_model.diam_mean,\n",
        "        channel_axis=None\n",
        "    )\n",
        "\n",
        "    print(\"Mask Segmentation Down!\")\n",
        "\n",
        "    # Export centroids\n",
        "    props = measure.regionprops_table['centroid', 'area']\n",
        "    props_dataframe = pd.DataFrame(props)\n",
        "    c_output_path = os.path.join(output_path, \"_centroids.csv\")\n",
        "\n",
        "    props_dataframe.to_csv(c_output_path)\n",
        "\n",
        "    print(\"Get Centroids Down!\")\n",
        "\n",
        "    # Save the masks as TIFF files\n",
        "    io.save_masks(\n",
        "        images=img,\n",
        "        masks=masks,\n",
        "        flows=flows,\n",
        "        file_names=output_path,\n",
        "        png=False,\n",
        "        tif=True,\n",
        "        channels=[0, 0]\n",
        "    )\n",
        "\n",
        "    print(\"Save Mask Down!\")\n",
        "\n",
        "    \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_images_in_folder(input_folder, output_folder, denoise_model, cellpose_model):\n",
        "    \"\"\"\n",
        "    Process all TIF images in a folder: denoise, segment, and save the output.\n",
        "\n",
        "    Parameters:\n",
        "    - input_folder (str): Path to the folder containing input images.\n",
        "    - output_folder (str): Path to save the processed output images.\n",
        "    - denoise_model: Pre-initialized denoising model.\n",
        "    - cellpose_model: Pre-initialized Cellpose segmentation model.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    \n",
        "    i = 0\n",
        "\n",
        "    # Ensure the output folder exists\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Find all TIF files in the input folder\n",
        "    file_paths = glob.glob(os.path.join(input_folder, \"*.tif\"))\n",
        "\n",
        "    for file_path in file_paths:\n",
        "        \n",
        "        # Read the image\n",
        "        # print(\"file_path:\", file_path)\n",
        "        img = tiff.imread(file_path)\n",
        "\n",
        "        # Get the base file name\n",
        "        file_name = os.path.basename(file_path)\n",
        "        # print(\"file_name:\", file_name)\n",
        "\n",
        "        file_base = os.path.splitext(file_name)[0]\n",
        "        # print(\"file_base:\", file_base)\n",
        "\n",
        "        file_base = \"cp_masks_\" + file_base\n",
        "        # print(\"file_base2:\", file_base)\n",
        "\n",
        "        # Define the output path for the current image\n",
        "        output_path = os.path.join(output_folder, file_base)\n",
        "        # print(\"output_path:\", output_path)\n",
        "\n",
        "        # Print the file name\n",
        "        print(f\"Processing image {i}\")\n",
        "\n",
        "        img_name = file_name\n",
        "        \n",
        "        # Run the denoise and segmentation function\n",
        "        denoise_and_segment_image(\n",
        "            img=img,\n",
        "            img_name=file_name,\n",
        "            output_path=output_path,   \n",
        "            denoise_model=denoise_model,\n",
        "            cellpose_model=cellpose_model\n",
        "        )\n",
        "\n",
        "        i += 1\n",
        "\n",
        "        print(f\"Output of {img_name} saved as: {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def process_images_in_folder(input_folder, output_folder, denoise_model, cellpose_model):\n",
        "    \"\"\"\n",
        "    Process all TIF images in a folder: denoise, segment, and save the output.\n",
        "    \"\"\"\n",
        "    i = 0\n",
        "\n",
        "    # Ensure the output folder exists\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    print(f\"Output folder created/verified: {output_folder}\")\n",
        "\n",
        "    # Find all TIF files in the input folder\n",
        "    file_paths = glob.glob(os.path.join(input_folder, \"*.tif\"))\n",
        "    print(f\"Found {len(file_paths)} TIF files in input folder\")\n",
        "\n",
        "    for file_path in file_paths:\n",
        "        try:\n",
        "            # Read the image\n",
        "            print(f\"\\nProcessing file: {file_path}\")\n",
        "            img = tiff.imread(file_path)\n",
        "            print(f\"Image shape: {img.shape}\")\n",
        "\n",
        "            # Get the base file name\n",
        "            file_name = os.path.basename(file_path)\n",
        "            file_base = os.path.splitext(file_name)[0]\n",
        "            file_base = \"cp_masks_\" + file_base\n",
        "            output_path = os.path.join(output_folder, file_base)\n",
        "\n",
        "            print(f\"Processing image {i}: {file_name}\")\n",
        "            print(f\"Output will be saved to: {output_path}\")\n",
        "\n",
        "            # Call the processing function\n",
        "            print(\"Calling denoise_and_segment_image...\")\n",
        "            result = denoise_and_segment_image(\n",
        "                img=img,\n",
        "                img_name=file_name,\n",
        "                output_path=output_path,   \n",
        "                denoise_model=denoise_model,\n",
        "                cellpose_model=cellpose_model\n",
        "            )\n",
        "            print(\"Finished processing image\")\n",
        "\n",
        "            i += 1\n",
        "            print(f\"Successfully processed [{file_name}]. Output saved as: {output_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {file_path}: {str(e)}\")\n",
        "            continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO test\n",
        "\n",
        "def check_files_in_folder(input_folder, output_folder, denoise_model, cellpose_model):\n",
        "    \"\"\"\n",
        "    Process all TIF images in a folder: denoise, segment, and save the output.\n",
        "    \"\"\"\n",
        "    # Print all contents of the input folder\n",
        "    print(f\"Contents of input folder {input_folder}:\")\n",
        "    for item in os.listdir(input_folder):\n",
        "        print(f\"- {item}\")\n",
        "\n",
        "    # Try different extensions\n",
        "    tif_files = []\n",
        "    tif_files.extend(glob.glob(os.path.join(input_folder, \"*.tif\")))\n",
        "    tif_files.extend(glob.glob(os.path.join(input_folder, \"*.tiff\")))\n",
        "    tif_files.extend(glob.glob(os.path.join(input_folder, \"*.TIF\")))\n",
        "    tif_files.extend(glob.glob(os.path.join(input_folder, \"*.TIFF\")))\n",
        "\n",
        "    print(f\"\\nFound {len(tif_files)} TIF files:\")\n",
        "    for file in tif_files:\n",
        "        print(f\"- {file}\")\n",
        "\n",
        "    # Check if the input_folder path is correct\n",
        "    print(f\"\\nFull input folder path: {os.path.abspath(input_folder)}\")\n",
        "\n",
        "    if len(tif_files) == 0:\n",
        "        print(\"\\nNo TIF files found. Please check:\")\n",
        "        print(\"1. The input folder path is correct\")\n",
        "        print(\"2. The files have the correct extension (.tif, .tiff, .TIF, or .TIFF)\")\n",
        "        print(\"3. You have read permissions for the folder\")\n",
        "        return\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output folder created/verified: output/cellpose\n",
            "Found 6 TIF files in input folder\n",
            "\n",
            "Processing file: input/cellpose\\E3H5_Round1_DAPI_tile1_inference.tif\n",
            "Image shape: (827, 1024, 1024)\n",
            "Processing image 0: E3H5_Round1_DAPI_tile1_inference.tif\n",
            "Output will be saved to: output/cellpose\\cp_masks_E3H5_Round1_DAPI_tile1_inference\n",
            "Calling denoise_and_segment_image...\n",
            "Processing file: E3H5_Round1_DAPI_tile1_inference.tif, shape: (827, 1024, 1024)\n",
            "Denoise Down!\n",
            "Mask Segmentation Down!\n",
            "Error processing input/cellpose\\E3H5_Round1_DAPI_tile1_inference.tif: 'function' object is not subscriptable\n",
            "\n",
            "Processing file: input/cellpose\\E3H5_Round1_DAPI_tile2_inference.tif\n",
            "Image shape: (827, 1024, 1024)\n",
            "Processing image 0: E3H5_Round1_DAPI_tile2_inference.tif\n",
            "Output will be saved to: output/cellpose\\cp_masks_E3H5_Round1_DAPI_tile2_inference\n",
            "Calling denoise_and_segment_image...\n",
            "Processing file: E3H5_Round1_DAPI_tile2_inference.tif, shape: (827, 1024, 1024)\n",
            "Denoise Down!\n",
            "Mask Segmentation Down!\n",
            "Error processing input/cellpose\\E3H5_Round1_DAPI_tile2_inference.tif: 'function' object is not subscriptable\n",
            "\n",
            "Processing file: input/cellpose\\E3H5_Round1_DAPI_tile3_inference.tif\n",
            "Image shape: (827, 1024, 1024)\n",
            "Processing image 0: E3H5_Round1_DAPI_tile3_inference.tif\n",
            "Output will be saved to: output/cellpose\\cp_masks_E3H5_Round1_DAPI_tile3_inference\n",
            "Calling denoise_and_segment_image...\n",
            "Processing file: E3H5_Round1_DAPI_tile3_inference.tif, shape: (827, 1024, 1024)\n",
            "Denoise Down!\n",
            "Mask Segmentation Down!\n",
            "Error processing input/cellpose\\E3H5_Round1_DAPI_tile3_inference.tif: 'function' object is not subscriptable\n",
            "\n",
            "Processing file: input/cellpose\\E3H5_Round1_DAPI_tile4_inference.tif\n",
            "Image shape: (827, 1024, 1024)\n",
            "Processing image 0: E3H5_Round1_DAPI_tile4_inference.tif\n",
            "Output will be saved to: output/cellpose\\cp_masks_E3H5_Round1_DAPI_tile4_inference\n",
            "Calling denoise_and_segment_image...\n",
            "Processing file: E3H5_Round1_DAPI_tile4_inference.tif, shape: (827, 1024, 1024)\n",
            "Denoise Down!\n",
            "Mask Segmentation Down!\n",
            "Error processing input/cellpose\\E3H5_Round1_DAPI_tile4_inference.tif: 'function' object is not subscriptable\n",
            "\n",
            "Processing file: input/cellpose\\E3H5_Round1_DAPI_tile5_inference.tif\n",
            "Image shape: (827, 1024, 1024)\n",
            "Processing image 0: E3H5_Round1_DAPI_tile5_inference.tif\n",
            "Output will be saved to: output/cellpose\\cp_masks_E3H5_Round1_DAPI_tile5_inference\n",
            "Calling denoise_and_segment_image...\n",
            "Processing file: E3H5_Round1_DAPI_tile5_inference.tif, shape: (827, 1024, 1024)\n",
            "Denoise Down!\n",
            "Mask Segmentation Down!\n",
            "Error processing input/cellpose\\E3H5_Round1_DAPI_tile5_inference.tif: 'function' object is not subscriptable\n",
            "\n",
            "Processing file: input/cellpose\\E3H5_Round1_DAPI_tile6_inference.tif\n",
            "Image shape: (827, 1024, 1024)\n",
            "Processing image 0: E3H5_Round1_DAPI_tile6_inference.tif\n",
            "Output will be saved to: output/cellpose\\cp_masks_E3H5_Round1_DAPI_tile6_inference\n",
            "Calling denoise_and_segment_image...\n",
            "Processing file: E3H5_Round1_DAPI_tile6_inference.tif, shape: (827, 1024, 1024)\n",
            "Denoise Down!\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mprocess_images_in_folder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput/cellpose\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput/cellpose\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdenoise_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdenoise_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcellpose_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcellpose_model\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[17], line 33\u001b[0m, in \u001b[0;36mprocess_images_in_folder\u001b[1;34m(input_folder, output_folder, denoise_model, cellpose_model)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Call the processing function\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling denoise_and_segment_image...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mdenoise_and_segment_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimg_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdenoise_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdenoise_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcellpose_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcellpose_model\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished processing image\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     42\u001b[0m i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "Cell \u001b[1;32mIn[15], line 35\u001b[0m, in \u001b[0;36mdenoise_and_segment_image\u001b[1;34m(img, img_name, output_path, denoise_model, cellpose_model)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDenoise Down!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Perform segmentation\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m masks, flows, styles \u001b[38;5;241m=\u001b[39m \u001b[43mcellpose_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimgs_dn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_3D\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiameter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcellpose_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiam_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchannel_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m     41\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMask Segmentation Down!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Export centroids\u001b[39;00m\n",
            "File \u001b[1;32md:\\Junwoo\\Conda\\envs\\cellpose\\lib\\site-packages\\cellpose\\models.py:543\u001b[0m, in \u001b[0;36mCellposeModel.eval\u001b[1;34m(self, x, batch_size, resample, channels, channel_axis, z_axis, normalize, invert, rescale, diameter, flow_threshold, cellprob_threshold, do_3D, anisotropy, dP_smooth, stitch_threshold, min_size, max_size_fraction, niter, augment, tile_overlap, bsize, interp, compute_masks, progress)\u001b[0m\n\u001b[0;32m    539\u001b[0m     masks \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m#pass back zeros if not compute_masks\u001b[39;00m\n\u001b[0;32m    541\u001b[0m masks, dP, cellprob \u001b[38;5;241m=\u001b[39m masks\u001b[38;5;241m.\u001b[39msqueeze(), dP\u001b[38;5;241m.\u001b[39msqueeze(), cellprob\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m--> 543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m masks, [\u001b[43mplot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdx_to_circ\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdP\u001b[49m\u001b[43m)\u001b[49m, dP, cellprob], styles\n",
            "File \u001b[1;32md:\\Junwoo\\Conda\\envs\\cellpose\\lib\\site-packages\\cellpose\\plot.py:36\u001b[0m, in \u001b[0;36mdx_to_circ\u001b[1;34m(dP)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdx_to_circ\u001b[39m(dP):\n\u001b[0;32m     27\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Converts the optic flow representation to a circular color representation.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m \n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m     mag \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize99\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdP\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1.\u001b[39m)\n\u001b[0;32m     37\u001b[0m     angles \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marctan2(dP[\u001b[38;5;241m1\u001b[39m], dP[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mpi\n\u001b[0;32m     38\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
            "File \u001b[1;32md:\\Junwoo\\Conda\\envs\\cellpose\\lib\\site-packages\\cellpose\\transforms.py:187\u001b[0m, in \u001b[0;36mnormalize99\u001b[1;34m(Y, lower, upper, copy, downsample)\u001b[0m\n\u001b[0;32m    185\u001b[0m     x99 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpercentile(X[slc], upper)\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 187\u001b[0m     x01 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpercentile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m     x99 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpercentile(X, upper)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x99 \u001b[38;5;241m-\u001b[39m x01 \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1e-3\u001b[39m:\n",
            "File \u001b[1;32md:\\Junwoo\\Conda\\envs\\cellpose\\lib\\site-packages\\numpy\\lib\\function_base.py:4283\u001b[0m, in \u001b[0;36mpercentile\u001b[1;34m(a, q, axis, out, overwrite_input, method, keepdims, interpolation)\u001b[0m\n\u001b[0;32m   4281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _quantile_is_valid(q):\n\u001b[0;32m   4282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPercentiles must be in the range [0, 100]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 4283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_quantile_unchecked\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4284\u001b[0m \u001b[43m    \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Junwoo\\Conda\\envs\\cellpose\\lib\\site-packages\\numpy\\lib\\function_base.py:4555\u001b[0m, in \u001b[0;36m_quantile_unchecked\u001b[1;34m(a, q, axis, out, overwrite_input, method, keepdims)\u001b[0m\n\u001b[0;32m   4547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_quantile_unchecked\u001b[39m(a,\n\u001b[0;32m   4548\u001b[0m                         q,\n\u001b[0;32m   4549\u001b[0m                         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4552\u001b[0m                         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   4553\u001b[0m                         keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   4554\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Assumes that q is in [0, 1], and is an ndarray\"\"\"\u001b[39;00m\n\u001b[1;32m-> 4555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ureduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4556\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_quantile_ureduce_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4557\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4558\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4559\u001b[0m \u001b[43m                    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4560\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4561\u001b[0m \u001b[43m                    \u001b[49m\u001b[43moverwrite_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4562\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Junwoo\\Conda\\envs\\cellpose\\lib\\site-packages\\numpy\\lib\\function_base.py:3823\u001b[0m, in \u001b[0;36m_ureduce\u001b[1;34m(a, func, keepdims, **kwargs)\u001b[0m\n\u001b[0;32m   3820\u001b[0m             index_out \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, ) \u001b[38;5;241m*\u001b[39m nd\n\u001b[0;32m   3821\u001b[0m             kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m out[(\u001b[38;5;28mEllipsis\u001b[39m, ) \u001b[38;5;241m+\u001b[39m index_out]\n\u001b[1;32m-> 3823\u001b[0m r \u001b[38;5;241m=\u001b[39m func(a, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3825\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
            "File \u001b[1;32md:\\Junwoo\\Conda\\envs\\cellpose\\lib\\site-packages\\numpy\\lib\\function_base.py:4722\u001b[0m, in \u001b[0;36m_quantile_ureduce_func\u001b[1;34m(a, q, axis, out, overwrite_input, method)\u001b[0m\n\u001b[0;32m   4720\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4721\u001b[0m         arr \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m-> 4722\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43m_quantile\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4723\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mquantiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4724\u001b[0m \u001b[43m                   \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4725\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4726\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4727\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[1;32md:\\Junwoo\\Conda\\envs\\cellpose\\lib\\site-packages\\numpy\\lib\\function_base.py:4824\u001b[0m, in \u001b[0;36m_quantile\u001b[1;34m(arr, quantiles, axis, method, out)\u001b[0m\n\u001b[0;32m   4820\u001b[0m previous_indexes, next_indexes \u001b[38;5;241m=\u001b[39m _get_indexes(arr,\n\u001b[0;32m   4821\u001b[0m                                               virtual_indexes,\n\u001b[0;32m   4822\u001b[0m                                               values_count)\n\u001b[0;32m   4823\u001b[0m \u001b[38;5;66;03m# --- Sorting\u001b[39;00m\n\u001b[1;32m-> 4824\u001b[0m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartition\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4825\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4826\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mprevious_indexes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4827\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mnext_indexes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4828\u001b[0m \u001b[43m                              \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4829\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m supports_nans:\n\u001b[0;32m   4831\u001b[0m     slices_having_nans \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39misnan(arr[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m])\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "process_images_in_folder(\n",
        "    input_folder=\"input/cellpose\",\n",
        "    output_folder=\"output/cellpose\",\n",
        "    denoise_model=denoise_model,\n",
        "    cellpose_model=cellpose_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cellpose",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
